{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71e2aa71",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "!pip install x-transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81c23f03",
   "metadata": {},
   "source": [
    "> Parameter configurations by iterative search and embeddings generation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "870c70ba",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import torch\n",
    "import numpy as np\n",
    "from x_transformers import ContinuousTransformerWrapper, Encoder\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.metrics import silhouette_score\n",
    "from itertools import product\n",
    "from sklearn.metrics import accuracy_score\n",
    "import joblib\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "\n",
    "\n",
    "path = \"../../data\"\n",
    "\n",
    "output_dir = '.'\n",
    "import os\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def split_sequence(tensor, window_size):\n",
    "    seq_len = tensor.shape[1]\n",
    "    return [tensor[:, i:i+window_size, :] for i in range(0, seq_len, window_size)]\n",
    "\n",
    "early_warning_url = f\"{path}/early_warning_exp_1.csv\"\n",
    "early_warning = pd.read_csv(early_warning_url, sep=\";\")\n",
    "colunas = [\n",
    "    'total_pacotes', 'total_pacotes_icmp', 'total_pacotes_udp', 'total_pacotes_tcp', 'maior_pacote',\n",
    "    'menor_pacote', 'soma_pacotes', 'total_ips_origem', 'total_ips_destino', 'porta_origem_mais_frequente',\n",
    "    'porta_destino_mais_frequente', 'total_mac_source', 'total_mac_dst', 'ip_version', 'maior_ttl', 'menor_ttl',\n",
    "    'std_ttl', 'mean_ttl', 'total_flags_tcp', 'total_tcp_flags_fin', 'total_tcp_flags_syn', 'total_tcp_flags_reset',\n",
    "    'total_tcp_flags_push', 'total_tcp_flags_ack', 'total_tcp_flags_urg', 'maior_tcp_window_size_value', 'menor_tcp_window_size_value',\n",
    "    'soma_tcp_window_size_value', 'std_tcp_window_size_value', 'mean_tcp_window_size_value', 'maior_tcp_seq', 'menor_tcp_seq', 'soma_tcp_seq',\n",
    "    'std_tcp_seq', 'mean_tcp_seq', 'maior_time_delta', 'menor_time_delta', 'soma_time_delta', 'std_time_delta', 'mean_time_delta',\n",
    "    'maior_tcp_time_delta', 'menor_tcp_time_delta', 'soma_tcp_time_delta', 'std_tcp_time_delta', 'mean_tcp_time_delta', 'maior_tcp_time_relative',\n",
    "    'menor_tcp_time_relative', 'soma_tcp_time_relative', 'std_tcp_time_relative', 'mean_tcp_time_relative'\n",
    "]\n",
    "\n",
    "\n",
    "dim = [ 128, 12, 32, 64,20]\n",
    "depth = [256, 128,32,16,64]\n",
    "heads = [64,12,20, 32,16] \n",
    "dim_out=[128,64, 12,20, 16]\n",
    "sup=0\n",
    "inf=5632\n",
    "\n",
    "melhor_score = -1\n",
    "melhores_parametros = {}\n",
    "melhor_y_pred = None\n",
    "y_test_real_melhor = None\n",
    "melhor_embeddings = None\n",
    "\n",
    "for dim_out, heads, depth, dim in product(dim_out, heads, depth, dim):\n",
    "    scaler = RobustScaler()\n",
    "    print(f\"\\n- Config: dim={dim}, depth={depth}, heads={heads}, dim_out={dim_out}\")\n",
    "    slice_init_unlabeled_test = sup\n",
    "    slice_end_unlabeled_test = inf\n",
    "\n",
    "    x_test_df = early_warning[colunas][slice_init_unlabeled_test:slice_end_unlabeled_test].copy()\n",
    "    y_test_real = early_warning['has_bot'][slice_init_unlabeled_test:slice_end_unlabeled_test].to_numpy()\n",
    "    x_test_normalized = scaler.fit_transform(x_test_df)\n",
    "    x_test_tensor = torch.tensor(x_test_normalized, dtype=torch.float32).unsqueeze(0)\n",
    "    num_features = x_test_tensor.shape[2]\n",
    "\n",
    "    model = ContinuousTransformerWrapper(\n",
    "        dim_in=num_features,\n",
    "        dim_out=dim_out,\n",
    "        max_seq_len=6000,  \n",
    "        attn_layers=Encoder(\n",
    "            dim=dim,\n",
    "            depth=depth,\n",
    "            heads=heads,\n",
    "            dynamic_pos_bias=True\n",
    "        )\n",
    "    )\n",
    "\n",
    "    windows = split_sequence(x_test_tensor, window_size=30)\n",
    "    embeddings_list = []\n",
    "    with torch.no_grad():\n",
    "        for window in windows:\n",
    "            mask = torch.ones_like(window[:, :, 0]).bool()\n",
    "            emb = model(window, mask=mask)\n",
    "            embeddings_list.append(emb.squeeze(0).cpu())\n",
    "\n",
    "    embeddings_test_np = torch.cat(embeddings_list, dim=0).numpy()\n",
    "\n",
    "    kmeans = KMeans(n_clusters=2, random_state=0, n_init='auto').fit(embeddings_test_np)\n",
    "    y_pred = kmeans.labels_\n",
    "\n",
    "    acc = accuracy_score(y_test_real, y_pred)\n",
    "    acc_inv = accuracy_score(y_test_real, 1 - y_pred)\n",
    "    acc_corrigida = max(acc, acc_inv)\n",
    "\n",
    "    print(f\"accuracy: {acc_corrigida:.4f}\")\n",
    "\n",
    "    if acc_corrigida > melhor_score:\n",
    "        melhor_score = acc_corrigida\n",
    "        melhores_parametros = {'dim': dim, 'depth': depth, 'heads': heads, 'init': {sup}, 'end': {inf}}\n",
    "        melhor_y_pred = y_pred if acc >= acc_inv else 1 - y_pred\n",
    "        melhor_embeddings = embeddings_test_np.copy()\n",
    "        y_test_real_melhor = y_test_real.copy()\n",
    "        embeddings_df = pd.DataFrame(melhor_embeddings)\n",
    "        embeddings_df.columns = [f'embedding_{i}' for i in range(embeddings_test_np.shape[1])]\n",
    "\n",
    "        melhor_df = x_test_df.copy()\n",
    "        melhor_df['predicted_label'] = melhor_y_pred\n",
    "        melhor_df['real_label'] = y_test_real_melhor\n",
    "\n",
    "        np.save(f'{output_dir}/embeddings_ex1.npy', melhor_embeddings)\n",
    "        embeddings_df.to_csv(f'{output_dir}/embeddings_ex1.csv', index=False)\n",
    "        melhor_df.to_csv(f'{output_dir}/resultado_ex1.csv', index=False)\n",
    "\n",
    "print(\"\\nBest Configuration:\")\n",
    "print(melhores_parametros)\n",
    "print(\"\\n - Confusion Matrix:\" )\n",
    "print(confusion_matrix(y_test_real_melhor, melhor_y_pred))\n",
    "print(\"\\n - Classification Report:\")\n",
    "print(classification_report(y_test_real_melhor, melhor_y_pred, digits=4, zero_division=0))\n",
    "\n",
    "score = silhouette_score(melhor_embeddings, melhor_y_pred)\n",
    "print(f\"\\n- Silhouette Score: {score:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
